{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": "# !pip install mlem torchvision tensorflow numpy torch torchaudio --upgrade\n# !pip install mlem==0.4.6 --no-deps\n# !pip install iterative-telemetry==0.0.7 --ignore-requires-python --no-deps\n# !pip install pydantic==1.10.2 --no-deps",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-14T12:10:33.062011Z",
          "iopub.execute_input": "2023-04-14T12:10:33.062367Z",
          "iopub.status.idle": "2023-04-14T12:12:44.004884Z",
          "shell.execute_reply.started": "2023-04-14T12:10:33.062331Z",
          "shell.execute_reply": "2023-04-14T12:12:44.003637Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "from __future__ import print_function\nfrom __future__ import division\n\nimport os\nimport copy\nimport typing\nimport datetime\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nfrom pathlib import Path\nfrom tqdm.notebook import tqdm\nfrom collections import OrderedDict\n\n# Нейронки\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nimport torchvision\nfrom torchvision import datasets, transforms\nfrom torchvision import transforms as torch_transforms\nfrom torchvision import io as torch_io\nfrom torchvision import models as torch_models\n\nprint(\"PyTorch Version: \",torch.__version__)\nprint(\"Torchvision Version: \",torchvision.__version__)",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-14T16:31:03.358611Z",
          "iopub.execute_input": "2023-04-14T16:31:03.359842Z",
          "iopub.status.idle": "2023-04-14T16:31:03.370166Z",
          "shell.execute_reply.started": "2023-04-14T16:31:03.359797Z",
          "shell.execute_reply": "2023-04-14T16:31:03.368862Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "# Параметры",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "class WorkingMode:\n    TRAIN: str = \"train\"\n    VAL: str = \"val\"",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-14T16:17:37.949176Z",
          "iopub.execute_input": "2023-04-14T16:17:37.949599Z",
          "iopub.status.idle": "2023-04-14T16:17:37.955024Z",
          "shell.execute_reply.started": "2023-04-14T16:17:37.949563Z",
          "shell.execute_reply": "2023-04-14T16:17:37.953534Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "INPUT_DIR: Path = Path(\"/kaggle/input/\")\nOUTPUT_DIR: Path = Path(\"/kaggle/working/\")\n\n# FINAL_DATASET_DIR: Path = INPUT_DIR / \"art-price\" / \"dataset\"\nFINAL_DATASET_DIR: Path = INPUT_DIR / \"chat-art-platform-dataset\" / \"final_data\"\nWORKING_MODES: typing.List[WorkingMode] = [WorkingMode.TRAIN, WorkingMode.VAL]\n\nDATASET_DIRS: typing.Dict[WorkingMode, Path] = {\n    mode: FINAL_DATASET_DIR / mode\n    for mode in WORKING_MODES\n}\nANNOTATIONS_PATHS: typing.Dict[WorkingMode, Path] = {\n    mode: FINAL_DATASET_DIR / f\"{mode}.csv\"\n    for mode in WORKING_MODES\n}\n    \nBATCH_SIZE: int = 64\nN_WORKERS: int = 2\nIMAGE_RESIZE_SIZE: int = 420\n\nMODELS_DIR: Path = OUTPUT_DIR / \"models\"\nMODELS_DIR.mkdir(parents=True, exist_ok=True)\n\nMODEL_CLASS: typing.Type[nn.Module] = torch_models.efficientnet_b3\nMODELS_WEIGHTS = torch_models.EfficientNet_B3_Weights.IMAGENET1K_V1\n\n# Detect if we have a GPU available\nDEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint(DEVICE)",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-14T16:27:21.002184Z",
          "iopub.execute_input": "2023-04-14T16:27:21.002605Z",
          "iopub.status.idle": "2023-04-14T16:27:21.013397Z",
          "shell.execute_reply.started": "2023-04-14T16:27:21.002569Z",
          "shell.execute_reply": "2023-04-14T16:27:21.012224Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "# Создание модели pytorch",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Выбрал модель классификации изображений https://pytorch.org/vision/stable/models.html#:~:text=EfficientNet_B3_Weights.IMAGENET1K_V1 как оптимальную по соотношению качество/скорость работы.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## Проверим модель",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "def predict_by_model(img_path: Path, model: nn.Module, transforms=None) -> torch.Tensor:\n    img = torch_io.read_image(str(img_path), mode=torch_io.image.ImageReadMode.RGB).to(DEVICE)\n    if transforms:\n        img = transforms(img)\n    \n    batch = img.unsqueeze(0)\n    \n    model.eval()\n    prediction = model(batch).squeeze(0)\n    \n    return prediction",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-14T16:27:24.280262Z",
          "iopub.execute_input": "2023-04-14T16:27:24.280976Z",
          "iopub.status.idle": "2023-04-14T16:27:24.287401Z",
          "shell.execute_reply.started": "2023-04-14T16:27:24.280936Z",
          "shell.execute_reply": "2023-04-14T16:27:24.286119Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "img_path: Path = DATASET_DIRS[WorkingMode.TRAIN] / \"19.png\"\n\n# Initialize model with the best available weights and the inference transforms\nmodel: nn.Module = MODEL_CLASS(weights=MODELS_WEIGHTS).to(DEVICE)\ntransforms = MODELS_WEIGHTS.transforms()\n\nprediction: torch.Tensor = predict_by_model(img_path=img_path, model=model, transforms=transforms)\nprobs: torch.Tensor = prediction.softmax(0)\n\n# Use the model and print the predicted category\nclass_id: int = prediction.argmax().item()\nscore = probs[class_id].item()\ncategory_name = MODELS_WEIGHTS.meta[\"categories\"][class_id]\nprint(f\"{category_name}: {100 * score:.1f}%\")",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-14T16:27:24.489706Z",
          "iopub.execute_input": "2023-04-14T16:27:24.490354Z",
          "iopub.status.idle": "2023-04-14T16:27:24.850335Z",
          "shell.execute_reply.started": "2023-04-14T16:27:24.490319Z",
          "shell.execute_reply": "2023-04-14T16:27:24.849182Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "## Load data",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "class ImagePricingDataset(Dataset):\n\n    def __init__(self, csv_path: Path, root_dir: Path, transform=None):\n        \"\"\"\n        Args:\n            csv_path: Path to the csv file with annotations.\n            root_dir: directory with all the images.\n            transform: Optional transform to be applied on a sample.\n        \"\"\"\n        self.df: pd.DataFrame = pd.read_csv(csv_path)\n        self.root_dir: Path = root_dir\n        self.transform = transform\n\n    def __len__(self):\n        return self.df.shape[0]\n\n    def __getitem__(self, idx):\n        if torch.is_tensor(idx):\n            idx = idx.tolist()\n        annotation: pd.Series = self.df.iloc[idx]\n        \n        img_path: Path = self.root_dir / annotation[\"image\"]\n        try:\n            image = torch_io.read_image(str(img_path), mode=torch_io.image.ImageReadMode.RGB)\n        except:\n#             print(img_path)\n            return self.__getitem__(idx=idx + 1)\n        if self.transform:\n            image = self.transform(image)\n        \n        price = annotation[\"price\"]\n        return {'image': image.float(), 'price': torch.tensor(price).float()}",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-14T17:45:43.707585Z",
          "iopub.execute_input": "2023-04-14T17:45:43.708709Z",
          "iopub.status.idle": "2023-04-14T17:45:43.719575Z",
          "shell.execute_reply.started": "2023-04-14T17:45:43.708655Z",
          "shell.execute_reply": "2023-04-14T17:45:43.718292Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "### Посмотрим на примеры (проверим ImagePricingDataset)",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "n_images: int = 5\ncommon_transform = torch_transforms.Compose([\n    torch_transforms.Resize(IMAGE_RESIZE_SIZE),\n    MODELS_WEIGHTS.transforms(),\n])\ntmp_dataset: ImagePricingDataset = ImagePricingDataset(\n    csv_path=ANNOTATIONS_PATHS[WorkingMode.TRAIN], \n    root_dir=DATASET_DIRS[WorkingMode.TRAIN], \n    transform=common_transform,\n#     transform=None,\n)\n    \nfig = plt.figure()\nfor i in range(len(tmp_dataset)):\n    sample = tmp_dataset[i]\n\n    print(i, sample['price'], sample['image'].shape, sample['price'].shape)\n\n    ax = plt.subplot(1, n_images, i + 1)\n    plt.tight_layout()\n    ax.set_title(f\"Sample #{i}, price={sample['price']}\")\n    ax.axis('off')\n    plt.imshow(sample['image'].permute(1, 2, 0))\n\n    if i == (n_images - 1):\n        plt.show()\n        break",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-14T17:50:30.116547Z",
          "iopub.execute_input": "2023-04-14T17:50:30.117276Z",
          "iopub.status.idle": "2023-04-14T17:50:30.635452Z",
          "shell.execute_reply.started": "2023-04-14T17:50:30.117237Z",
          "shell.execute_reply": "2023-04-14T17:50:30.634423Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "DataLoader(ImagePricingDataset)",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "tmp_dataset: ImagePricingDataset = ImagePricingDataset(\n    csv_path=ANNOTATIONS_PATHS[WorkingMode.TRAIN], \n    root_dir=DATASET_DIRS[WorkingMode.TRAIN], \n    transform=torch_transforms.CenterCrop(200),\n)\ntmp_dataloader: DataLoader = DataLoader(tmp_dataset, batch_size=5, shuffle=False, num_workers=0)\n\nfor i, batch in enumerate(tmp_dataloader):\n    print(i, batch[\"image\"].size(), batch[\"price\"].size(), batch[\"price\"])\n    if i == 2:\n        break",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-14T17:50:36.274614Z",
          "iopub.execute_input": "2023-04-14T17:50:36.276811Z",
          "iopub.status.idle": "2023-04-14T17:50:36.461678Z",
          "shell.execute_reply.started": "2023-04-14T17:50:36.276755Z",
          "shell.execute_reply": "2023-04-14T17:50:36.460409Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "## Аугментации",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "AUGNENTATION_PROB: float = 0.5\nGRAY_PROB: float = 0.2\nBLUR_PROB: float = 1.0\nNOISE_PROB: float = 0.2\n\nBLUR_SIGMA: float = 2.0\nBLUR_KERNEL_SIZE: typing.Tuple[int, int] = (21, 21)\nNOISE_FACTOR: float = 0.1\n\n\ndef add_noise(inputs: torch.Tensor, noise_factor: float = 0.2) -> torch.Tensor:\n    print(\"inputs:\", inputs)\n    max_noise: int = int(255 * noise_factor)\n    noise = torch.randint_like(inputs.float(), high=max_noise)\n    noisy = torch.clip(inputs + noise, 0, 255)\n    print(\"noise:\", noise)\n    print(\"noisy:\", noisy)\n    return noisy\n\ndef noise_wrap(inputs: torch.Tensor) -> torch.Tensor:\n    return add_noise(inputs=inputs, noise_factor=NOISE_FACTOR)\n\n\naugmenters_list = [\n    torch_transforms.RandomApply([torch_transforms.GaussianBlur(kernel_size=BLUR_KERNEL_SIZE, sigma=BLUR_SIGMA)], p=BLUR_PROB),\n#     torch_transforms.RandomApply([torch_transforms.Lambda(noise_wrap)], p=NOISE_PROB),\n    torch_transforms.RandomGrayscale(p=GRAY_PROB),\n]",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-14T17:50:55.256562Z",
          "iopub.execute_input": "2023-04-14T17:50:55.256967Z",
          "iopub.status.idle": "2023-04-14T17:50:55.266826Z",
          "shell.execute_reply.started": "2023-04-14T17:50:55.256930Z",
          "shell.execute_reply": "2023-04-14T17:50:55.265611Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "## DataLoadres",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "print(\"Initializing Datasets and Dataloaders...\")\n\ncommon_transform = torch_transforms.Compose([\n    torch_transforms.Resize(IMAGE_RESIZE_SIZE),\n    MODELS_WEIGHTS.transforms(),\n])\ndata_transforms = {\n    WorkingMode.TRAIN: torch_transforms.Compose([\n        torchvision.transforms.RandomApply(augmenters_list, p=AUGNENTATION_PROB), \n        common_transform,\n    ]),\n    WorkingMode.VAL: common_transform,\n}\n\n# Create training and validation datasets\nimage_datasets: typing.Dict[WorkingMode, ImagePricingDataset] = {\n    mode: ImagePricingDataset(\n        csv_path=ANNOTATIONS_PATHS[mode], \n        root_dir=DATASET_DIRS[mode], \n        transform=data_transforms[mode],\n    )\n    for mode in WORKING_MODES\n}\n\n# Create training and validation dataloaders\ndataloaders: typing.Dict[WorkingMode, DataLoader] = {\n    mode: DataLoader(image_datasets[mode], batch_size=BATCH_SIZE, shuffle=True, num_workers=N_WORKERS) \n    for mode in WORKING_MODES\n}",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-14T17:51:00.233891Z",
          "iopub.execute_input": "2023-04-14T17:51:00.234674Z",
          "iopub.status.idle": "2023-04-14T17:51:00.269745Z",
          "shell.execute_reply.started": "2023-04-14T17:51:00.234632Z",
          "shell.execute_reply": "2023-04-14T17:51:00.268711Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "# Создадим модель для дообучения",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "def set_parameter_requires_grad(model: nn.Module, requires_grad: bool = False):\n    for param in model.parameters():\n        param.requires_grad = False",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-14T17:51:00.294328Z",
          "iopub.execute_input": "2023-04-14T17:51:00.295376Z",
          "iopub.status.idle": "2023-04-14T17:51:00.301216Z",
          "shell.execute_reply.started": "2023-04-14T17:51:00.295333Z",
          "shell.execute_reply": "2023-04-14T17:51:00.299973Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "def create_model(model_class: typing.Type[nn.Module], weights, freeze_body: bool = True) -> nn.Module:\n    model: nn.Module = model_class(weights=weights)\n    print(f\"Orig classiffier layer (last layer): \\n{model.classifier}\\n\")\n    \n    if freeze_body:\n        set_parameter_requires_grad(model=model, requires_grad=False)\n\n    n_in_features: int = model.classifier[1].in_features\n    model.classifier[1] = nn.Linear(n_in_features, 1)\n    print(f\"New classiffier layer (last layer): \\n{model.classifier}\")\n    \n    return model",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-14T17:51:00.335213Z",
          "iopub.execute_input": "2023-04-14T17:51:00.335523Z",
          "iopub.status.idle": "2023-04-14T17:51:00.344449Z",
          "shell.execute_reply.started": "2023-04-14T17:51:00.335471Z",
          "shell.execute_reply": "2023-04-14T17:51:00.343385Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "model: nn.Module = create_model(model_class=MODEL_CLASS, weights=MODELS_WEIGHTS, freeze_body=True)",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-14T17:51:02.063824Z",
          "iopub.execute_input": "2023-04-14T17:51:02.064601Z",
          "iopub.status.idle": "2023-04-14T17:51:02.357294Z",
          "shell.execute_reply.started": "2023-04-14T17:51:02.064560Z",
          "shell.execute_reply": "2023-04-14T17:51:02.356065Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "## Model saving/loading",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "def save_model_weights(model: nn.Module, model_name: str, model_dir: Path) -> Path:\n    model_dir.mkdir(parents=True, exist_ok=True)\n    weights_path: Path = model_dir / f\"{model_name}_weights.pt\"\n\n    torch.save(model.state_dict(), weights_path)\n    \n    return weights_path\n\n\ndef load_from_weights(model: nn.Module, weights_path: Path) -> nn.Module:\n    \"\"\"Only weights.\"\"\"\n    model.load_state_dict(torch.load(weights_path))\n    model.eval()\n    return model\n\n# def save_model(model: nn.Module, model_name: str, model_dir: Path) -> typing.Tuple[Path, Path]:\n#     model_dir.mkdir(parents=True, exist_ok=True)\n#     weights_path: Path = model_dir / f\"{model_name}_weights.pt\"\n#     model_path: Path = model_dir / f\"{model_name}_model.pt\"\n\n#     torch.save(model.state_dict(), weights_path)\n#     torch.save(model, model_path)\n    \n#     return weights_path, model_path\n\n# def load_model(model_path: Path) -> nn.Module:\n#     \"\"\"!!!Like pickle => use class name for loading => don't work, because we change last layer?.\"\"\"\n#     model: nn.Module = torch.load(final_model_path)\n#     model.eval()\n#     return model",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-14T17:51:02.359798Z",
          "iopub.execute_input": "2023-04-14T17:51:02.360464Z",
          "iopub.status.idle": "2023-04-14T17:51:02.367572Z",
          "shell.execute_reply.started": "2023-04-14T17:51:02.360422Z",
          "shell.execute_reply": "2023-04-14T17:51:02.366363Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "model_name: str = \"dummy\"\nmodel_dir: Path = MODELS_DIR / model_name\n\ndummy_model: nn.Module = create_model(model_class=MODEL_CLASS, weights=MODELS_WEIGHTS, freeze_body=True).to(DEVICE)\nweights_path = save_model_weights(dummy_model, model_name=model_name, model_dir=model_dir)\n\n# Load\nnew_model: nn.Module = create_model(model_class=MODEL_CLASS, weights=MODELS_WEIGHTS, freeze_body=True)\nnew_model = load_from_weights(model=new_model, weights_path=weights_path).to(DEVICE)\nprint(\"Loaded from weights\")\n\n\n# # Strict model\n# other_model: nn.Module = load_model(model_path)\n# print(\"Loaded model\")",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-14T17:51:02.369506Z",
          "iopub.execute_input": "2023-04-14T17:51:02.370348Z",
          "iopub.status.idle": "2023-04-14T17:51:03.256978Z",
          "shell.execute_reply.started": "2023-04-14T17:51:02.370243Z",
          "shell.execute_reply": "2023-04-14T17:51:03.255777Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "img_path: Path = DATASET_DIRS[WorkingMode.TRAIN] / \"19.png\"\ntransforms = MODELS_WEIGHTS.transforms()\n\ndummy_prediction: torch.Tensor = predict_by_model(img_path=img_path, model=dummy_model, transforms=transforms)\nnew_prediction: torch.Tensor = predict_by_model(img_path=img_path, model=new_model, transforms=transforms)\n# other_prediction: torch.Tensor = predict_by_model(img_path=img_path, model=other_model, transforms=transforms)\n\nprint(dummy_prediction, new_prediction)",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-14T17:51:03.259308Z",
          "iopub.execute_input": "2023-04-14T17:51:03.259956Z",
          "iopub.status.idle": "2023-04-14T17:51:03.330830Z",
          "shell.execute_reply.started": "2023-04-14T17:51:03.259880Z",
          "shell.execute_reply": "2023-04-14T17:51:03.329655Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "### Оптимизатор",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "def create_optimizer(model, lr=0.001):\n    print(\"Params to learn:\")\n    params_to_update = []\n    for name, param in model.named_parameters():\n        if param.requires_grad == True:\n            params_to_update.append(param)\n            print(\"\\t\",name)\n\n    # Observe that all parameters are being optimized\n    optimizer = optim.Adam(params_to_update, lr=lr)\n    return optimizer",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-14T17:51:05.827430Z",
          "iopub.execute_input": "2023-04-14T17:51:05.828644Z",
          "iopub.status.idle": "2023-04-14T17:51:05.835880Z",
          "shell.execute_reply.started": "2023-04-14T17:51:05.828586Z",
          "shell.execute_reply": "2023-04-14T17:51:05.834384Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "# Обучение модели",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "def plot_hist(y_true: np.ndarray, y_pred: np.ndarray, title: str = None):\n    preds = pd.DataFrame({'y_true': y_true, 'y_pred': y_pred})\n    kwargs = dict(kind=\"hist\", bins=100, alpha=0.5, figsize=(6, 3), title=title)\n    preds.plot(**kwargs)\n    plt.show()",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-14T17:51:06.054669Z",
          "iopub.execute_input": "2023-04-14T17:51:06.055331Z",
          "iopub.status.idle": "2023-04-14T17:51:06.061390Z",
          "shell.execute_reply.started": "2023-04-14T17:51:06.055296Z",
          "shell.execute_reply": "2023-04-14T17:51:06.060224Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "def rmsle(y_true: torch.Tensor, y_pred: torch.Tensor) -> torch.Tensor:\n    return torch.mean((torch.log10(y_true) - torch.log10(y_pred))**2)",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-14T17:51:06.216005Z",
          "iopub.execute_input": "2023-04-14T17:51:06.216330Z",
          "iopub.status.idle": "2023-04-14T17:51:06.222023Z",
          "shell.execute_reply.started": "2023-04-14T17:51:06.216297Z",
          "shell.execute_reply": "2023-04-14T17:51:06.220791Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "def run_epoch(\n    working_mode: WorkingMode, \n    model: nn.Module, \n    dataloader: DataLoader, \n    criterion, \n    optimizer, \n    num_epochs: int = 5,\n) -> float:\n    \"\"\"Run one full epoch of train/val process.\"\"\"\n    start_date: datetime.datetime = datetime.datetime.now()\n    print(f\"{working_mode} start time: {start_date}\")\n\n    is_train: bool = (working_mode == WorkingMode.TRAIN)\n    if is_train:\n        model.train()  # Set model to training mode\n    else:\n        model.eval()   # Set model to evaluate mode\n\n    sum_std_err_running_loss: float = 0.0\n    sum_std_log_err_running_loss: float = 0.0\n    dataset_size: int = len(dataloader.dataset)\n    \n    true_log_prices: list[np.ndarray] = []\n    pred_log_prices: list[np.ndarray] = []\n\n    # Iterate over data.\n    for batch in tqdm(dataloader, total=dataset_size // dataloader.batch_size):\n        inputs = batch[\"image\"].to(DEVICE)\n        prices = batch[\"price\"].to(DEVICE)\n\n        log_prices = torch.log10(prices)\n\n        # zero the parameter gradients\n        optimizer.zero_grad()\n\n        # forward\n        # track history if only in train\n        with torch.set_grad_enabled(is_train):\n            # Get model outputs and calculate loss\n\n            log_pred_prices = model(inputs).reshape(-1)\n            loss = criterion(log_pred_prices, log_prices)\n\n            pred_prices = torch.pow(10, log_pred_prices).detach()\n\n            # backward + optimize only if in training phase\n            if is_train:\n                loss.backward()\n                optimizer.step()\n            \n            true_log_prices.append(log_prices.detach().to(\"cpu\").numpy())\n            pred_log_prices.append(log_pred_prices.detach().to(\"cpu\").numpy())\n\n        # statistics\n        sum_std_err_running_loss += loss.to(\"cpu\").item() * inputs.size(0)\n        sum_std_log_err_running_loss += ((torch.log10(prices) - torch.log10(pred_prices))**2).sum().to(\"cpu\").item()\n#         break\n\n    epoch_rmse: float = np.sqrt(sum_std_err_running_loss / dataset_size)\n    epoch_rmsle: float = np.sqrt(sum_std_log_err_running_loss / dataset_size)\n    \n    plot_hist(\n        y_true=np.concatenate(true_log_prices), \n        y_pred=np.concatenate(pred_log_prices),\n        title=f\"Log price; {working_mode}; RMSLE={epoch_rmsle:.4f}\",\n    )\n\n    end_date: datetime.datetime = datetime.datetime.now()\n    time_delta: datetime.timedelta = end_date - start_date\n    print(f\"Epoch complete in {time_delta}\")\n    print(f\"{working_mode} RMSLE: {epoch_rmsle:.4f}, RMSE: {epoch_rmse:.4f}\")\n    \n    return epoch_rmsle",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-14T17:51:07.319425Z",
          "iopub.execute_input": "2023-04-14T17:51:07.320077Z",
          "iopub.status.idle": "2023-04-14T17:51:07.334267Z",
          "shell.execute_reply.started": "2023-04-14T17:51:07.320040Z",
          "shell.execute_reply": "2023-04-14T17:51:07.332423Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "N_EPOCHES: int = 100\nstart_epoch: int = 48\nLR: float = 0.001\n\nmodel_name: str = \"full_dataset_resize\"\nmodel_dir: Path = MODELS_DIR / model_name\ninterupted_models_dir: Path = MODELS_DIR / \"interupted\"",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-14T17:51:07.337136Z",
          "iopub.execute_input": "2023-04-14T17:51:07.337978Z",
          "iopub.status.idle": "2023-04-14T17:51:07.346648Z",
          "shell.execute_reply.started": "2023-04-14T17:51:07.337937Z",
          "shell.execute_reply": "2023-04-14T17:51:07.345545Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "model: nn.Module = create_model(model_class=MODEL_CLASS, weights=MODELS_WEIGHTS, freeze_body=True)\n\n# load strict model\nweights_path: Path = Path(\n    '/kaggle/working/models/full_dataset/best_full_dataset_rmsle=0.4546_epoch=48_2023-04-14 16:10:34.150201_weights.pt'\n)\nmodel = load_from_weights(model=model, weights_path=weights_path)\n\nmodel.to(DEVICE)\n\noptimizer = create_optimizer(model=model, lr=LR)\ncriterion = nn.MSELoss()",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-14T17:51:07.358235Z",
          "iopub.execute_input": "2023-04-14T17:51:07.358531Z",
          "iopub.status.idle": "2023-04-14T17:51:07.794778Z",
          "shell.execute_reply.started": "2023-04-14T17:51:07.358497Z",
          "shell.execute_reply": "2023-04-14T17:51:07.793551Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "start_date: datetime.datetime = datetime.datetime.now()\nprint(f\"Start time: {start_date}\")\n\nval_rmsle_history = []\n\nbest_model_wts = copy.deepcopy(model.state_dict())\nbest_rmsle = np.inf\n\nfor epoch in range(start_epoch, N_EPOCHES + 1):\n    try:\n        print(\"-\" * 80)\n        print(f\"Epoch {epoch}/{N_EPOCHES}\")\n        print(\"-\" * 80)\n\n        # Each epoch has a training and validation phase\n        for mode in WORKING_MODES:\n            epoch_rmsle: float = run_epoch(\n                working_mode=mode,\n                model=model, \n                dataloader=dataloaders[mode], \n                criterion=criterion, \n                optimizer=optimizer,\n            )\n\n            # deep copy the model\n            if mode == WorkingMode.VAL:\n                val_rmsle_history.append(epoch_rmsle)\n\n                if epoch_rmsle < best_rmsle:\n                    best_rmsle = epoch_rmsle\n                    best_model_wts = copy.deepcopy(model.state_dict())\n                    weights_path = save_model_weights(\n                        model=model, \n                        model_name=f\"best_{model_name}_rmsle={best_rmsle:.4f}_epoch={epoch}_{datetime.datetime.now()}\", \n                        model_dir=model_dir,\n                    )\n\n        end_date: datetime.datetime = datetime.datetime.now()\n        time_delta: datetime.timedelta = end_date - start_date\n        print(f\"Epoch complete in {time_delta}\")\n        print(f\"Best rmsle: {best_rmsle:4f}\")\n        print(\"\\n\")\n        \n    except KeyboardInterrupt:\n        weights_path = save_model_weights(\n            model=model, \n            model_name=f\"INTERRUPTED_{model_name}_last_rmsle={epoch_rmsle:.4f}_epoch={epoch}_{datetime.datetime.now()}\", \n            model_dir=interupted_models_dir,\n        )\n        print('Saved interrupted model')\n        raise KeyboardInterrupt",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-14T17:51:07.796821Z",
          "iopub.execute_input": "2023-04-14T17:51:07.797474Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "# Выберем модель",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "ls_command: str = f\"ls {model_dir}\"\nprint(ls_command)\nos.system(ls_command)",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-14T16:14:57.575620Z",
          "iopub.execute_input": "2023-04-14T16:14:57.576011Z",
          "iopub.status.idle": "2023-04-14T16:14:58.578909Z",
          "shell.execute_reply.started": "2023-04-14T16:14:57.575972Z",
          "shell.execute_reply": "2023-04-14T16:14:58.577385Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "weights_path: Path = Path(\n    '/kaggle/working/models/full_dataset/best_full_dataset_rmsle=0.4546_epoch=48_2023-04-14 16:10:34.150201_weights.pt'\n)\nnew_model: nn.Module = create_model(model_class=MODEL_CLASS, weights=MODELS_WEIGHTS, freeze_body=True)\nnew_model = load_from_weights(model=new_model, weights_path=weights_path)\nnew_model.to(DEVICE)\npass",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-14T16:15:11.120438Z",
          "iopub.execute_input": "2023-04-14T16:15:11.121541Z",
          "iopub.status.idle": "2023-04-14T16:15:12.086647Z",
          "shell.execute_reply.started": "2023-04-14T16:15:11.121491Z",
          "shell.execute_reply": "2023-04-14T16:15:12.085455Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "# Посмотрим прогнозы моделью",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "img_path: Path = DATASET_DIRS[WorkingMode.TRAIN] / \"35.png\"\nlog_price: torch.Tensor = predict_by_model(img_path=img_path, model=model, transforms=transforms)\nprice: float = torch.pow(10, log_price).item()\n\nprint(f\"{price:.2f}$\")\nImage.open(img_path)",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-14T16:15:14.197673Z",
          "iopub.execute_input": "2023-04-14T16:15:14.198048Z",
          "iopub.status.idle": "2023-04-14T16:15:14.369892Z",
          "shell.execute_reply.started": "2023-04-14T16:15:14.198014Z",
          "shell.execute_reply": "2023-04-14T16:15:14.368970Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "# Запакуем в MLEM",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## Предсказание по картинке",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "import io\nfrom PIL import Image\n\nimg_path: Path = DATASET_DIRS[WorkingMode.TRAIN] / \"35.png\"\nimg_bytes: bytes = img_path.read_bytes()\n\n\ndef mlem_predict(img_bytes: bytes):\n    image = Image.open(io.BytesIO(img_bytes)).convert('RGB')\n    transform = torch_transforms.Compose([torch_transforms.PILToTensor(), data_transforms[WorkingMode.VAL]])\n    img: torch.Tensor = transform(image).to(\"cpu\").float()\n    batch: torch.Tensor = img.unsqueeze(0)\n    \n    new_model.to(\"cpu\")\n    new_model.eval()\n    \n    log_price: torch.Tensor = new_model(batch).squeeze(0)\n    price: float = torch.pow(10, log_price).item()\n    \n    return {\"price\": price}\n\nprice: float = mlem_predict(img_bytes=img_bytes)[\"price\"]\nprint(f\"{price:.2f}$\")\nImage.open(img_path)",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-14T16:15:19.186072Z",
          "iopub.execute_input": "2023-04-14T16:15:19.186444Z",
          "iopub.status.idle": "2023-04-14T16:15:19.538573Z",
          "shell.execute_reply.started": "2023-04-14T16:15:19.186411Z",
          "shell.execute_reply": "2023-04-14T16:15:19.537343Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "## Сохранение",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "!pip install mlem --upgrade\n!pip install mlem==0.4.6 --no-deps\n!pip install iterative-telemetry==0.0.7 --ignore-requires-python --no-deps\n!pip install pydantic==1.10.2 --no-deps",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-14T16:15:22.755811Z",
          "iopub.execute_input": "2023-04-14T16:15:22.756561Z",
          "iopub.status.idle": "2023-04-14T16:15:40.327965Z",
          "shell.execute_reply.started": "2023-04-14T16:15:22.756520Z",
          "shell.execute_reply": "2023-04-14T16:15:40.326631Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "import os\nfrom mlem.api import save\n\nmlem_path: Path = model_dir / f\"mlem_{model_name}\"\nsave(\n    mlem_predict, \n    mlem_path, \n    sample_data=img_bytes,\n);",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-14T16:15:50.845875Z",
          "iopub.execute_input": "2023-04-14T16:15:50.846349Z",
          "iopub.status.idle": "2023-04-14T16:15:53.950858Z",
          "shell.execute_reply.started": "2023-04-14T16:15:50.846299Z",
          "shell.execute_reply": "2023-04-14T16:15:53.949108Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "zip_command: str = f\"zip -r {mlem_path.name}.zip {mlem_path}.mlem {mlem_path}\"\nprint(zip_command)\nos.system(zip_command)",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-14T16:16:35.116702Z",
          "iopub.execute_input": "2023-04-14T16:16:35.117859Z",
          "iopub.status.idle": "2023-04-14T16:16:37.549312Z",
          "shell.execute_reply.started": "2023-04-14T16:16:35.117796Z",
          "shell.execute_reply": "2023-04-14T16:16:37.548169Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "mlem_path",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-14T16:16:37.551566Z",
          "iopub.execute_input": "2023-04-14T16:16:37.551952Z",
          "iopub.status.idle": "2023-04-14T16:16:37.559753Z",
          "shell.execute_reply.started": "2023-04-14T16:16:37.551913Z",
          "shell.execute_reply": "2023-04-14T16:16:37.558617Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "## Скачаем zip с mlem моделью",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "from IPython.display import FileLink\nos.chdir(OUTPUT_DIR)\nFileLink(f\"{mlem_path.name}.zip\")",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-14T16:16:43.249410Z",
          "iopub.execute_input": "2023-04-14T16:16:43.250684Z",
          "iopub.status.idle": "2023-04-14T16:16:43.260312Z",
          "shell.execute_reply.started": "2023-04-14T16:16:43.250616Z",
          "shell.execute_reply": "2023-04-14T16:16:43.257925Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    }
  ]
}